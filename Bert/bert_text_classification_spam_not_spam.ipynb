{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "61256b40-c2df-4f73-98c4-7757672a7edb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL 4\\bert-env\\lib\\site-packages\\huggingface_hub\\file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Step 1: Sample Data\n",
    "data = {\n",
    "    'label': ['ham', 'spam', 'ham', 'spam', 'ham', 'spam', 'ham', 'ham', 'spam', 'ham',\n",
    "              'spam', 'ham', 'ham', 'spam', 'ham', 'spam', 'ham', 'ham', 'spam', 'ham'],\n",
    "    'text': [\n",
    "        \"Hi there, how are you?\", \n",
    "        \"WINNER!! You've won a free ticket. Text WIN to 12345\",\n",
    "        \"Are we still on for dinner tonight?\", \n",
    "        \"Congratulations! You've been selected for a prize.\",\n",
    "        \"Don't forget our meeting tomorrow.\", \n",
    "        \"You have been chosen to receive a free gift!\",\n",
    "        \"Can you send me the report?\", \n",
    "        \"Call me when you get this.\", \n",
    "        \"Get your free ringtone now!\", \n",
    "        \"Looking forward to our trip.\",\n",
    "        \"Free entry in 2 a weekly competition! Text WIN to 80086 now\",\n",
    "        \"Thanks for your help today.\",\n",
    "        \"Happy birthday! Have a great one.\", \n",
    "        \"You've won $1000 cash!\", \n",
    "        \"See you at the game later.\",\n",
    "        \"Claim your reward at spamoffers.com\", \n",
    "        \"Lunch at 1 PM works for me.\", \n",
    "        \"Can we talk later?\", \n",
    "        \"URGENT! Act now to claim your prize.\",\n",
    "        \"Hey, letâ€™s catch up soon!\"\n",
    "    ]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "df['label'] = df['label'].map({'ham': 0, 'spam': 1})\n",
    "\n",
    "# Step 2: Train/Test Split before tokenizing\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['text'], df['label'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 3: Tokenize using BERT tokenizer\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "train_encodings = tokenizer(list(X_train), truncation=True, padding=True, return_tensors=\"tf\")\n",
    "test_encodings = tokenizer(list(X_test), truncation=True, padding=True, return_tensors=\"tf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a5a8e34f-61fb-45af-97eb-d0cbf76343cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "4/4 [==============================] - 37s 3s/step - loss: 0.7029 - accuracy: 0.5625 - val_loss: 0.6274 - val_accuracy: 0.7500\n",
      "Epoch 2/2\n",
      "4/4 [==============================] - 7s 2s/step - loss: 0.5257 - accuracy: 0.8750 - val_loss: 0.5226 - val_accuracy: 0.7500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f43eabf7f0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Step 4: Create TensorFlow dataset\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((dict(train_encodings), list(y_train))).batch(4)\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((dict(test_encodings), list(y_test))).batch(4)\n",
    "\n",
    "# Step 5: Load BERT model\n",
    "from transformers import TFBertForSequenceClassification\n",
    "\n",
    "model = TFBertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
    "\n",
    "# Step 6: Compile\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=2e-5),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Step 7: Train\n",
    "model.fit(train_dataset, validation_data=test_dataset, epochs=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f4793e10-8903-444e-b848-95a814d0bd05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "its a Spam message \n",
      "its a normal message\n"
     ]
    }
   ],
   "source": [
    "def predict_spam(text):\n",
    "    tokens = tokenizer(text, truncation=True, padding=True, return_tensors=\"tf\")\n",
    "    output = model(**tokens)\n",
    "    prediction = tf.argmax(output.logits, axis=1).numpy()[0]\n",
    "    return \"its a Spam message \" if prediction == 1 else \"its a normal message\"\n",
    "\n",
    "# Try it out\n",
    "print(predict_spam(\"You won a lottery! Claim now\"))\n",
    "print(predict_spam(\"Hey, just checking in.\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23f9b61-b1d2-4a69-a0f9-83d68359f087",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (bert-env)",
   "language": "python",
   "name": "bert-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
